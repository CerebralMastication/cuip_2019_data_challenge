---
title: "CUIP 2019 Data Challenge"
author: "JD Long"
date: "8/22/2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This is an html render of the `index.Rmd` located here: https://github.com/CerebralMastication/cuip_2019_data_challenge

A preview of the whole dataset is in this repo. Let's pull in the data and take a look at it. 

Load up a few libraries
```{r include=FALSE}
library(tidyverse)
library(ggthemes) 
library(skimr)
library(janitor)
library(GGally)
```

## Air Quality Data

Grab the air quality data then give it a quick `skim` (from the `skimr` package):

```{r echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
air_quality <- read_csv("01_data/CSCDC+Dataset+Preview/air_quality_csv/all.csv")

skim(air_quality)  %>% kable()
```

Let's make these field names better so we don't have to quote these later. Using `janitor::clean_names()` to do the dirty work. And we have a bunch of fields with 2_5 in the name so let's look at those. 

```{r fig.height=10, fig.width=10, message=FALSE, warning=FALSE}
air_quality %>% 
  clean_names() %>% 
  select(timestamp_iso, nicename, p_2_5_um, p_2_5_um_b, pm2_5_atm, pm2_5_atm_b, pm2_5_cf_1, pm2_5_cf_1_b, current_temp_f, current_humidity) ->
  aq_limited

ggpairs(aq_limited)
```

Well that's kind of interesting. I'm not sure what the different pm2.5 related fields mean. Maybe we can find out. 

Let's look at a few of these individually. 

```{r}

ggplot(aq_limited) +
 aes(x = timestamp_iso, y = p_2_5_um) +
 geom_line(size = 1.92, colour = "#0c4c8a") +
 labs(x = "Date & Time", y = "Sensor Level", title = "`p_2_5_um` by Station") +
 theme_minimal() +
 facet_wrap(vars(nicename))

```

I don't know what it means exactly, but I bet there's hella traffic at douglas compared to the other stations. The volatility there is off the hook (comparatively)

Let's look at the same data layed on the same graph. It looks like they all move together:


```{r}

ggplot(aq_limited) +
 aes(x = timestamp_iso, y = p_2_5_um, color = nicename) +
 geom_line(size = 1.2) +
 labs(x = "Date & Time", y = "Sensor Level", title = "`p_2_5_um` by Station") +
 theme_minimal() +
 scale_colour_calc()

```


Well taht's sort of noisy. I wonder what the correlation is. Let's reshape the data to look at correlations quickly. 

Do a quick reshape of the data to get the stations in columns
```{r}

aq_limited %>%
  select(timestamp_iso, nicename, p_2_5_um) %>%
  spread(nicename, p_2_5_um ) %>% head(10) %>% kable()
```

Oh... the data is irregular. Ok, so we need to put this junk in buckets. I'm thinking maybe 5 min buckets? Let's see if we can do that. Feels like a job for grouping by a floor value. We can get the 15 minute interval floors from the `lubridate` package. 

```{r}

library(lubridate)


aq_limited %>%
  select(timestamp_iso, nicename, p_2_5_um) %>%
  spread(nicename, p_2_5_um) %>%
  group_by(timemark = floor_date(timestamp_iso, "10 mins")) %>%
  select(-timestamp_iso) %>%
  summarize_all(mean, na.rm = TRUE) ->
  aq_limited_wide

kable(aq_limited_wide)


```

That looks better. Pretty short time period, of course. Only an hour of data. This will be more interesting with more data later. But we're just figuring out what's going on right now. 

Now let's plot and look at the pairs plot with correlations:

```{r fig.height=10, fig.width=10}
aq_limited_wide %>%
  select(-timemark) %>%
  ggpairs()
```



Since we're slicing and dicing, let's look at temp vs. p_2_5_um for each station:

```{r}
ggplot(aq_limited) +
 aes(x = current_temp_f, y = p_2_5_um) +
 geom_point(size = 1.92, colour = "#0c4c8a") +
 labs(x = "Temp (F)", y = "Sensor Level", title = "`p_2_5_um` vs Temp (F)") +
 theme_minimal() +
 facet_wrap(vars(nicename))


```


That's not as insightful as I had hoped. Let's look at humidity:


```{r}
ggplot(aq_limited) +
 aes(x = current_humidity, y = p_2_5_um) +
 geom_point(size = 1.92, colour = "#0c4c8a") +
 labs(x = "Absolute Humidity", y = "Sensor Level", title = "`p_2_5_um` vs Humidity") +
 theme_minimal() +
 facet_wrap(vars(nicename))


```

we see the striping in temp because temps are reported as whole integers only. Makes for a funny pattern. 


So what is PM 2.5? Well I didn't know so I googled that junk. Came up with this helpful link:
https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm

Looks like it's a level of 2.5 micron and smaller particulate matter. The article says it's sensitive to wind levels. This is not overly surprising. There's no atheists in foxholes and no air quality warnings in a hurricane. 

I don't know where this data was collected, but I suspect it was around Chattanooga. Let's plot the locations and see:

```{r message=FALSE, warning=FALSE}
library(ggmap)
library(sf)
library(mapview)
library(leaflet)
```

```{r}
# grap the coordinates
air_quality %>%
  group_by(nicename, lat, lon) %>%
  summarize(obs_count = n()) ->
  obs_location

# turn them into a spatial sf object for mapping
obs_location_sf <-
  st_as_sf(obs_location,
           coords = c("lon", "lat"),
           crs = 4326)

# build the map
m1 <- mapview(obs_location_sf, legend = FALSE)

# add the names as labels
l1  <- addStaticLabels(
  m1,
  label = obs_location_sf$nicename,
  textsize = "20px",
  direction = 'left'
)

l1
```

Cool, they are all right up one strip in Chattanooga. I guess now we know what the MLK prefix in all the station names stands for. Looks like the stations are named after MLK and the cross street. Makes sense. 

## Video Events

We'll do the same with the video events:

```{r echo=TRUE, message=FALSE, warning=FALSE, results='asis'}
video_events <- read_csv("01_data/CSCDC+Dataset+Preview/video_event_csv/all.csv")
skim(video_events)  %>% kable()
```


